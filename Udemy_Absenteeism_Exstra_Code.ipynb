{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKQP3DOg7GBz2YXsEQd2VU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolai5965/Absenteeism-Prediction-Model/blob/main/Udemy_Absenteeism_Exstra_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here one can get some more info about the data: "
      ],
      "metadata": {
        "id": "7RTiYLx8vqu9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xER0xEcxvG0m"
      },
      "outputs": [],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "Use pandas_profilling to generate a report on the dataset, so I can see the results in Google Colab:\n",
        "profile = ProfileReport(df, title='Pandas Profiling Report', html={'style':{'full_width':True}}) \n",
        "profile.to_notebook_iframe() # display the report in the notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I have used this next code to see which hyperparameters would be the best: "
      ],
      "metadata": {
        "id": "hxqWPlGRvqkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "optimizer = tf.keras.optimizers.legacy.Adam()\n",
        "\n",
        "\n",
        "# Define a list of hyperparameters to test\n",
        "hidden_layer_sizes = [32, 64, 128]\n",
        "l2_lambdas = [0.0001, 0.001, 0.01]\n",
        "batch_sizes = [16, 32, 64]\n",
        "dropout_rates = [0.2, 0.4, 0.6]\n",
        "validation_split = 0.2\n",
        "# Create an array to store the results\n",
        "results = []\n",
        "\n",
        "for hidden_layer_size in hidden_layer_sizes:\n",
        "    for l2_lambda in l2_lambdas:\n",
        "        for batch_size in batch_sizes:\n",
        "            for dropout_rate in dropout_rates:\n",
        "                # Create the model with the current hyperparameters\n",
        "                model = tf.keras.Sequential([\n",
        "                    tf.keras.layers.Dense(hidden_layer_size, activation='relu', input_shape=(input_size,), kernel_regularizer=regularizers.l2(l2_lambda)),\n",
        "                    tf.keras.layers.LayerNormalization(),\n",
        "                    tf.keras.layers.Dropout(dropout_rate),\n",
        "                    tf.keras.layers.Dense(hidden_layer_size, activation='relu', kernel_regularizer=regularizers.l2(l2_lambda)),\n",
        "                    tf.keras.layers.LayerNormalization(),\n",
        "                    tf.keras.layers.Dropout(dropout_rate),\n",
        "                    tf.keras.layers.Dense(output_size, activation='sigmoid', kernel_regularizer=regularizers.l2(l2_lambda))\n",
        "                ])\n",
        "\n",
        "                # Compile and fit the model\n",
        "                model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
        "                history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, verbose=0, validation_split=validation_split, callbacks=[early_stopping])\n",
        "\n",
        "                # Evaluate the model on the test set\n",
        "                test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "                # Store the results\n",
        "                results.append({\n",
        "                    'hidden_layer_size': hidden_layer_size,\n",
        "                    'l2_lambda': l2_lambda,\n",
        "                    'batch_size': batch_size,\n",
        "                    'dropout_rate': dropout_rate,\n",
        "                    'train_accuracy': np.max(history.history['accuracy']),\n",
        "                    'val_accuracy': np.max(history.history['val_accuracy']),\n",
        "                    'test_accuracy': test_accuracy\n",
        "                })\n",
        "\n",
        "# Convert the results to a Pandas DataFrame for easier analysis\n",
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "display(results_df)\n",
        "display(results_df.describe())\n",
        "best_val_idx = results_df['val_accuracy'].idxmax()\n",
        "best_params = results_df.loc[best_val_idx]\n",
        "print(\"Best hyperparameters:\")\n",
        "print(best_params)"
      ],
      "metadata": {
        "id": "CXMmMLpjv1kd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}